{"cells":[{"cell_type":"code","execution_count":null,"id":"847d6622-f5d2-45ab-b781-33a65391617b","metadata":{"id":"847d6622-f5d2-45ab-b781-33a65391617b"},"outputs":[],"source":["import unicodedata\n","import re\n","import math\n","import psutil\n","import time\n","import datetime\n","from io import open\n","import random\n","from random import shuffle\n","import argparse\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","import torch.cuda\n","\n","\"\"\"this line clears sys to allow for argparse to work as gradient clipper\"\"\"\n","import sys; sys.argv=['']; del sys"]},{"cell_type":"code","execution_count":null,"id":"fc5fcc87","metadata":{"id":"fc5fcc87"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"8cb2b731-c799-4315-8679-a27cfdcae295","metadata":{"id":"8cb2b731-c799-4315-8679-a27cfdcae295"},"outputs":[],"source":["def normalizeString(s):\n","\n","    # special_chars = \"!,@#$%^&*()_+-={}|[]:;\\\"'<>,.?/~`.,;?!$¬£‚Ç¨‚Çπ¬ß¬©¬Æ‚Ñ¢‚Ä¢\"\n","    special_chars = \"‚ÅÑ‚Ä°‚Ä†‡•§!,@#$%^&*()_+-={}|[]:;\\\"'<>,.?/~`.,;?!$¬£‚Ç¨‚Çπ¬ß¬©¬Æ‚Ñ¢‚Ä¢‚Åá‚Üê‚Üë‚Üí‚àö‚â§‚â•‚ñ∫‚óè„ÄÅÊµ∑üôÇüôèíÜúìäâÍßÇÍßÅìäàíÜú¬•\"\n","\n","\n","    # Create a translation table for removing special characters\n","    translator = str.maketrans('', '', special_chars)\n","\n","    # Remove unwanted spaces, but keep Nepali characters intact\n","    s = re.sub(r\"\\s+\", \" \", s)  # Replace multiple spaces with a single space\n","    s = s.lower()\n","    s = s.translate(translator)\n","\n","    return s"]},{"cell_type":"code","execution_count":null,"id":"f9576b4f","metadata":{"id":"f9576b4f"},"outputs":[],"source":["def filterPair(p, max_length):\n","    if len(p) != 2:\n","        return False  # Skip invalid pairs\n","    return len(p[0].split(' ')) < max_length and len(p[1].split(' ')) < max_length\n"]},{"cell_type":"code","execution_count":null,"id":"aa376daa-06fb-4856-8736-d55194296ceb","metadata":{"id":"aa376daa-06fb-4856-8736-d55194296ceb"},"outputs":[],"source":["\"\"\"Filters all of the input-output language pairs in the dataset using filterPair\n","for each pair (from pytorch)\"\"\"\n","\n","def filterPairs(pairs, max_length):\n","    return [pair for pair in pairs if filterPair(pair, max_length)]"]},{"cell_type":"code","execution_count":null,"id":"9e5eab19-3d2b-468d-a4ce-68c5d945e70a","metadata":{"id":"9e5eab19-3d2b-468d-a4ce-68c5d945e70a"},"outputs":[],"source":["\"\"\"start of sentence tag\"\"\"\n","SOS_token = 0\n","\n","\"\"\"end of sentence tag\"\"\"\n","EOS_token = 1\n","\n","\"\"\"unknown word tag (this is used to handle words that are not in our Vocabulary)\"\"\"\n","UNK_token = 2\n","\n","\n","\"\"\"Lang class, used to store the vocabulary of each language\"\"\"\n","class Lang:\n","    def __init__(self, language):\n","        self.language_name = language\n","        self.word_to_index = {\"SOS\":SOS_token, \"EOS\":EOS_token, \"<UNK>\":UNK_token}\n","        self.word_to_count = {}\n","        self.index_to_word = {SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token: \"<UNK>\"}\n","        self.vocab_size = 3\n","        self.cutoff_point = -1\n","\n","\n","    def countSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.countWords(word)\n","\n","    \"\"\"counts the number of times each word appears in the dataset\"\"\"\n","    def countWords(self, word):\n","        if word not in self.word_to_count:\n","            self.word_to_count[word] = 1\n","        else:\n","            self.word_to_count[word] += 1\n","\n","    \"\"\"if the number of unique words in the dataset is larger than the\n","    specified max_vocab_size, creates a cutoff point that is used to\n","    leave infrequent words out of the vocabulary\"\"\"\n","    def createCutoff(self, max_vocab_size):\n","        word_freqs = list(self.word_to_count.values())\n","        word_freqs.sort(reverse=True)\n","        if len(word_freqs) > max_vocab_size:\n","            self.cutoff_point = word_freqs[max_vocab_size]\n","\n","    \"\"\"assigns each unique word in a sentence a unique index\"\"\"\n","    def addSentence(self, sentence):\n","        new_sentence = ''\n","        for word in sentence.split(' '):\n","            unk_word = self.addWord(word)\n","            if not new_sentence:\n","                new_sentence =unk_word\n","            else:\n","                new_sentence = new_sentence + ' ' + unk_word\n","        return new_sentence\n","\n","    \"\"\"assigns a word a unique index if not already in vocabulary\n","    and it appeaars often enough in the dataset\n","    (self.word_to_count is larger than self.cutoff_point)\"\"\"\n","    def addWord(self, word):\n","        if self.word_to_count[word] > self.cutoff_point:\n","            if word not in self.word_to_index:\n","                self.word_to_index[word] = self.vocab_size\n","                self.index_to_word[self.vocab_size] = word\n","                self.vocab_size += 1\n","            return word\n","        else:\n","            return self.index_to_word[2]"]},{"cell_type":"code","execution_count":null,"id":"84361d4d-a586-4db3-a3c3-c04356f1fe70","metadata":{"id":"84361d4d-a586-4db3-a3c3-c04356f1fe70"},"outputs":[],"source":["'''prepares both the input and output Lang classes from the passed dataset. file_path=2 means we have english and nepali\n","pairs in different files, also we can reverse the input andf output langugae, i.e with same data we can tranlate nepali to\n","english using this feature.\n","'''\n","\n","def prepareLangs(lang1, lang2, file_path, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    if len(file_path) == 2:\n","        lang1_lines = open(file_path[0], encoding='utf-8').\\\n","            read().strip().split('\\n')\n","\n","        lang2_lines = open(file_path[1], encoding='utf-8').\\\n","            read().strip().split('\\n')\n","\n","        if len(lang1_lines) != len(lang2_lines):\n","            print(\"Input and output text sizes do not align\")\n","            print(\"Number of lang1 lines: %s \" %len(lang1_lines))\n","            print(\"Number of lang2 lines: %s \" %len(lang2_lines))\n","            quit()\n","\n","        pairs = []\n","\n","        for line in range(len(lang1_lines)):\n","            pairs.append([normalizeString(lang1_lines[line]),\n","                          normalizeString(lang2_lines[line])])\n","\n","\n","    elif len(file_path) == 1:\n","        lines = open(file_path[0], encoding='utf-8').\\\n","    \tread().strip().split('\\n')\n","        pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs\n"]},{"cell_type":"code","execution_count":null,"id":"a32a91e3-30fe-45b1-8fb5-28ca5f8b8d7b","metadata":{"id":"a32a91e3-30fe-45b1-8fb5-28ca5f8b8d7b"},"outputs":[],"source":["\n","\"\"\"completely prepares both input and output languages\n","and returns cleaned and trimmed train and test pairs. for checking lets set max_vocab_size=1000 only. \"\"\"\n","\n","def prepareData(lang1, lang2, file_path, max_vocab_size=50000,\n","                reverse=False, trim=0, perc_train_set=0.9,\n","                print_to=None):\n","\n","    input_lang, output_lang, pairs = prepareLangs(lang1, lang2,\n","                                                  file_path, reverse)\n","\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","\n","    if print_to:\n","        with open(print_to,'a') as f:\n","            f.write(\"Read %s sentence pairs \\n\" % len(pairs))\n","\n","    if trim != 0:\n","        pairs = filterPairs(pairs, trim)\n","        print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","        if print_to:\n","            with open(print_to,'a') as f:\n","                f.write(\"Read %s sentence pairs \\n\" % len(pairs))\n","\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.countSentence(pair[0])\n","        output_lang.countSentence(pair[1])\n","\n","\n","    input_lang.createCutoff(max_vocab_size)\n","    output_lang.createCutoff(max_vocab_size)\n","\n","    pairs = [(input_lang.addSentence(pair[0]),output_lang.addSentence(pair[1]))\n","             for pair in pairs]\n","\n","    shuffle(pairs)\n","\n","    train_pairs = pairs[:math.ceil(perc_train_set*len(pairs))]\n","    test_pairs = pairs[math.ceil(perc_train_set*len(pairs)):]\n","\n","    print(\"Train pairs: %s\" % (len(train_pairs)))\n","    print(\"Test pairs: %s\" % (len(test_pairs)))\n","    print(\"Counted Words -> Trimmed Vocabulary Sizes (w/ EOS and SOS tags):\")\n","    print(\"%s, %s -> %s\" % (input_lang.language_name, len(input_lang.word_to_count),\n","                            input_lang.vocab_size,))\n","    print(\"%s, %s -> %s\" % (output_lang.language_name, len(output_lang.word_to_count),\n","                            output_lang.vocab_size))\n","    print()\n","\n","    if print_to:\n","        with open(print_to,'a') as f:\n","            f.write(\"Train pairs: %s\" % (len(train_pairs)))\n","            f.write(\"Test pairs: %s\" % (len(test_pairs)))\n","            f.write(\"Counted Words -> Trimmed Vocabulary Sizes (w/ EOS and SOS tags):\")\n","            f.write(\"%s, %s -> %s\" % (input_lang.language_name,\n","                                      len(input_lang.word_to_count),\n","                                      input_lang.vocab_size,))\n","            f.write(\"%s, %s -> %s \\n\" % (output_lang.language_name, len(output_lang.word_to_count),\n","                            output_lang.vocab_size))\n","\n","    return input_lang, output_lang, train_pairs, test_pairs"]},{"cell_type":"code","execution_count":null,"id":"ce0b59a4-ccb9-40cf-916c-163281c98c00","metadata":{"id":"ce0b59a4-ccb9-40cf-916c-163281c98c00"},"outputs":[],"source":["\"\"\"converts a sentence to one hot encoding vectors - pytorch allows us to just\n","use the number corresponding to the unique index for that word,\n","rather than a complete one hot encoding vector for each word\"\"\"\n","def indexesFromSentence(lang, sentence):\n","    indexes = []\n","    for word in sentence.split(' '):\n","        try:\n","            indexes.append(lang.word_to_index[word])\n","        except:\n","            indexes.append(lang.word_to_index[\"<UNK>\"])\n","    return indexes\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    result = torch.LongTensor(indexes).view(-1)\n","    if use_cuda:\n","        return result.cuda()\n","    else:\n","        return result\n","\n","\"\"\"converts a pair of sentence (input and target) to a pair of tensors\"\"\"\n","def tensorsFromPair(input_lang, output_lang, pair):\n","    input_variable = tensorFromSentence(input_lang, pair[0])\n","    target_variable = tensorFromSentence(output_lang, pair[1])\n","    return (input_variable, target_variable)\n","\n","\n","\"\"\"converts from tensor of one hot encoding vector indices to sentence\"\"\"\n","def sentenceFromTensor(lang, tensor):\n","    raw = tensor.data\n","    words = []\n","    for num in raw:\n","        words.append(lang.index_to_word[num.item()])\n","    return ' '.join(words)"]},{"cell_type":"code","execution_count":null,"id":"52250804-24b5-4a25-bc70-f953b4798c59","metadata":{"id":"52250804-24b5-4a25-bc70-f953b4798c59"},"outputs":[],"source":["\"\"\"seperates data into batches of size batch_size\"\"\"\n","def batchify(data, input_lang, output_lang, batch_size, shuffle_data=True):\n","    if shuffle_data == True:\n","        shuffle(data)\n","    number_of_batches = len(data) // batch_size\n","    batches = list(range(number_of_batches))\n","    longest_elements = list(range(number_of_batches))\n","\n","    for batch_number in range(number_of_batches):\n","        longest_input = 0\n","        longest_target = 0\n","        input_variables = list(range(batch_size))\n","        target_variables = list(range(batch_size))\n","        index = 0\n","        for pair in range((batch_number*batch_size),((batch_number+1)*batch_size)):\n","            input_variables[index], target_variables[index] = tensorsFromPair(input_lang, output_lang, data[pair])\n","            if len(input_variables[index]) >= longest_input:\n","                longest_input = len(input_variables[index])\n","            if len(target_variables[index]) >= longest_target:\n","                longest_target = len(target_variables[index])\n","            index += 1\n","        batches[batch_number] = (input_variables, target_variables)\n","        longest_elements[batch_number] = (longest_input, longest_target)\n","    return batches , longest_elements, number_of_batches\n","\n","\n","\"\"\"pads batches to allow for sentences of variable lengths to be computed in parallel\"\"\"\n","def pad_batch(batch):\n","    padded_inputs = torch.nn.utils.rnn.pad_sequence(batch[0],padding_value=EOS_token)\n","    padded_targets = torch.nn.utils.rnn.pad_sequence(batch[1],padding_value=EOS_token)\n","\n","    # print(f\"Input batch shape after padding: {padded_inputs.shape}\")\n","    # print(f\"Target batch shape after padding: {padded_targets.shape}\")\n","\n","    return (padded_inputs, padded_targets)"]},{"cell_type":"code","execution_count":null,"id":"y85n6mXLCn5s","metadata":{"id":"y85n6mXLCn5s"},"outputs":[],"source":["def calculate_wer(reference, hypothesis):\n","    \"\"\"\n","    Calculate the Word Error Rate (WER) between a reference and hypothesis sentence.\n","    WER = (S + D + I) / N, where\n","    S = Substitutions, D = Deletions, I = Insertions, N = Total number of words in reference.\n","    \"\"\"\n","    reference = reference.split()  # Assuming sentences are tokenized by spaces\n","    hypothesis = hypothesis.split()\n","\n","    # Create a matrix of size (len(reference)+1) x (len(hypothesis)+1)\n","    dp = np.zeros((len(reference) + 1, len(hypothesis) + 1))\n","\n","    # Initialize the first row and column of the dp matrix\n","    for i in range(len(reference) + 1):\n","        dp[i][0] = i\n","    for j in range(len(hypothesis) + 1):\n","        dp[0][j] = j\n","\n","    # Fill the dp matrix using the edit distance algorithm\n","    for i in range(1, len(reference) + 1):\n","        for j in range(1, len(hypothesis) + 1):\n","            if reference[i - 1] == hypothesis[j - 1]:\n","                dp[i][j] = dp[i - 1][j - 1]\n","            else:\n","                dp[i][j] = min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1]) + 1\n","\n","    # The value in the bottom right corner is the WER\n","    return dp[len(reference)][len(hypothesis)] / float(len(reference))\n"]},{"cell_type":"code","execution_count":null,"id":"2c0b00ba-e879-43d9-8ac5-65063ed0a206","metadata":{"id":"2c0b00ba-e879-43d9-8ac5-65063ed0a206"},"outputs":[],"source":["\n","def save_checkpoint(epoch, encoder, decoder, encoder_optimizer, decoder_optimizer, path=\"50k_model.pth\"):\n","    torch.save({\n","        'epoch': epoch,\n","        'encoder_state_dict': encoder.state_dict(),\n","        'decoder_state_dict': decoder.state_dict(),\n","        'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n","        'decoder_optimizer_state_dict': decoder_optimizer.state_dict()\n","    }, path)\n","\n","def load_checkpoint(path=\"50k_model.pth\"):\n","    checkpoint = torch.load(path)\n","    epoch = checkpoint['epoch']\n","    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n","    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n","    encoder_optimizer.load_state_dict(checkpoint['encoder_optimizer_state_dict'])\n","    decoder_optimizer.load_state_dict(checkpoint['decoder_optimizer_state_dict'])\n","    return epoch\n"]},{"cell_type":"code","execution_count":null,"id":"731c77c2-6355-46c1-8b65-efd5fea86c57","metadata":{"id":"731c77c2-6355-46c1-8b65-efd5fea86c57"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.autograd import Variable\n","\n","class EncoderRNNManual(nn.Module):\n","    def __init__(self, input_size, hidden_size, bidirectional, layers, dropout):\n","        super(EncoderRNNManual, self).__init__()\n","\n","        # Set directions for bidirectionality\n","        self.directions = 2 if bidirectional else 1\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = layers\n","        self.dropout_rate = dropout\n","\n","        # Initialize embedding layer and dropout\n","        self.embedder = nn.Embedding(input_size, hidden_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # Replace LSTM with custom LSTMCell\n","        self.lstm_cell = nn.LSTM(\n","            input_size=hidden_size,\n","            hidden_size=hidden_size,\n","            num_layers=layers,\n","            dropout=dropout,\n","            bidirectional=bidirectional,\n","            batch_first=False\n","        )\n","        self.fc = nn.Linear(hidden_size * self.directions, hidden_size)\n","\n","    # Actual forward code\n","    def forward(self, input_data, h_hidden, c_hidden):\n","        embedded_data = self.embedder(input_data)\n","        embedded_data = self.dropout(embedded_data)\n","        hiddens, outputs = self.lstm_cell(embedded_data, (h_hidden, c_hidden))\n","\n","        return hiddens, outputs\n","\n","    def create_init_hiddens(self, batch_size):\n","        # Create initial hidden and cell states for the encoder\n","        h_hidden = Variable(torch.zeros(self.num_layers * self.directions, batch_size, self.hidden_size))\n","        c_hidden = Variable(torch.zeros(self.num_layers * self.directions, batch_size, self.hidden_size))\n","\n","        if torch.cuda.is_available():\n","            return h_hidden.cuda(), c_hidden.cuda()\n","        else:\n","            return h_hidden, c_hidden\n"]},{"cell_type":"code","execution_count":null,"id":"39d58786-8538-4a83-8b72-e50b4df4a650","metadata":{"id":"39d58786-8538-4a83-8b72-e50b4df4a650"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class DecoderAttnManual(nn.Module):\n","    def __init__(self, hidden_size, output_size, layers, dropout, bidirectional):\n","        super(DecoderAttnManual, self).__init__()\n","\n","        # Attributes and embeddings initialization\n","        self.directions = 2 if bidirectional else 1\n","        self.output_size = output_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = layers\n","        self.dropout = dropout\n","        self.embedder = nn.Embedding(output_size, hidden_size)\n","        self.dropout_layer = nn.Dropout(dropout)\n","        self.score_learner = nn.Linear(hidden_size * self.directions, hidden_size * self.directions)\n","        self.lstm_cell = nn.LSTM(\n","            input_size=hidden_size,\n","            hidden_size=hidden_size,\n","            num_layers=layers,\n","            dropout=dropout,\n","            bidirectional=bidirectional,\n","            batch_first=False\n","        )\n","\n","        # Additional layers\n","        self.context_combiner = nn.Linear((hidden_size * self.directions) + (hidden_size * self.directions), hidden_size)\n","        self.tanh = nn.Tanh()\n","        self.output = nn.Linear(hidden_size, output_size)\n","        self.soft = nn.Softmax(dim=1)\n","        self.log_soft = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input_data, h_hidden, c_hidden, encoder_hiddens):\n","    # Embedding the input token\n","        embedded_data = self.embedder(input_data)\n","        embedded_data = self.dropout_layer(embedded_data)\n","        batch_size = embedded_data.shape[1]\n","\n","    # Run LSTM cell\n","        outputs, (hiddens, c_hiddens) = self.lstm_cell(embedded_data, (h_hidden, c_hidden))\n","\n","    # Compute attention scores\n","        prep_scores = self.score_learner(encoder_hiddens.permute(1, 0, 2))\n","        scores = torch.bmm(prep_scores, outputs.permute(1, 2, 0))\n","        attn_scores = self.soft(scores)\n","\n","    # Compute context matrix and combined hidden state\n","        con_mat = torch.bmm(encoder_hiddens.permute(1, 2, 0), attn_scores)\n","        h_tilde = self.tanh(\n","            self.context_combiner(torch.cat((con_mat.permute(0, 2, 1), outputs.permute(1, 0, 2)), dim=2))\n","        )\n","\n","        # Final prediction (shape: [batch_size, 1, vocab_size])\n","        pred = self.output(h_tilde)\n","\n","        # Squeeze to remove the unnecessary dimension (shape: [batch_size, vocab_size])\n","        pred = pred.squeeze(1)\n","\n","        # Log softmax for prediction\n","        pred = self.log_soft(pred)\n","\n","        return pred, (hiddens, c_hiddens)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c6f2d8c9-31d8-48e4-bb54-65d5b27efa0a","metadata":{"id":"c6f2d8c9-31d8-48e4-bb54-65d5b27efa0a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b6324c7d-55a4-48f6-b66f-d77c85bed470","metadata":{"id":"b6324c7d-55a4-48f6-b66f-d77c85bed470"},"outputs":[],"source":["def train_batch(input_batch, target_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, device='cuda'):\n","    # Move input and target batches to the device\n","    input_batch = input_batch.to(device)\n","    target_batch = target_batch.to(device)\n","\n","    # Zero the gradients for the optimizers\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Initialize encoder hidden states and move them to the device\n","    enc_h_hidden, enc_c_hidden = encoder.create_init_hiddens(input_batch.shape[1])\n","    enc_h_hidden, enc_c_hidden = enc_h_hidden.to(device), enc_c_hidden.to(device)\n","\n","    # Forward pass through encoder with nn.LSTM\n","    enc_hiddens, enc_outputs = encoder(input_batch, enc_h_hidden, enc_c_hidden)\n","\n","    # Set initial decoder input to SOS token for each sequence in the batch\n","    decoder_input = torch.LongTensor(1, input_batch.shape[1]).fill_(output_lang.word_to_index.get(\"SOS\")).to(device)\n","\n","    # Use encoder's final states as initial states for the decoder\n","    dec_h_hidden, dec_c_hidden = enc_outputs\n","\n","    # Initialize loss accumulator\n","    total_loss = 0\n","\n","    # Loop through each time step in the target sequence\n","    for i in range(target_batch.shape[0]):\n","        # Forward pass through decoder, collecting prediction logit\n","        pred, (dec_h_hidden, dec_c_hidden) = decoder(decoder_input, dec_h_hidden, dec_c_hidden, enc_hiddens)\n","\n","        # Squeeze the second dimension (index 1) of pred\n","        pred = pred.squeeze(1)  # Remove the middle singleton dimension\n","\n","        # Compute the loss for the current time step\n","        loss = criterion(pred, target_batch[i])  # pred and target are on the same device\n","        total_loss += loss\n","\n","        # Teacher forcing: use the actual target as the next input\n","        decoder_input = target_batch[i].view(1, -1)  # [1, batch_size] for the next time step\n","\n","    # Perform backpropagation\n","    total_loss.backward()\n","\n","    # Clip gradients to prevent exploding gradients\n","    torch.nn.utils.clip_grad_norm_(encoder.parameters(), 1.0)\n","    torch.nn.utils.clip_grad_norm_(decoder.parameters(), 1.0)\n","\n","    # Update encoder and decoder parameters\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return total_loss.item() / target_batch.shape[0]\n"]},{"cell_type":"code","execution_count":null,"id":"ccd7c76e","metadata":{"id":"ccd7c76e"},"outputs":[],"source":["def train(train_batches, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, output_lang, device='cuda'):\n","    round_loss = 0\n","    i = 1\n","\n","    for batch in train_batches:\n","        i += 1\n","        input_batch, target_batch = pad_batch(batch)\n","\n","        # Move data to the specified device\n","        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n","\n","        # Compute batch loss using train_batch function\n","        batch_loss = train_batch(\n","            input_batch, target_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, device=device\n","        )\n","\n","        round_loss += batch_loss\n","\n","    return round_loss / (len(train_batches) + 0.0001)\n"]},{"cell_type":"code","execution_count":null,"id":"6af818a1","metadata":{"id":"6af818a1"},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","def test_batch(input_batch, target_batch, encoder, decoder, output_lang, device='cuda'):\n","    # Move input and target batches to the specified device\n","    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n","\n","    # Track predictions and references for WER calculation\n","    all_predictions = []\n","    all_references = []\n","\n","    # Initialize encoder hidden states and encode input\n","    enc_h_hidden, enc_c_hidden = encoder.create_init_hiddens(input_batch.shape[1])\n","    enc_h_hidden, enc_c_hidden = enc_h_hidden.to(device), enc_c_hidden.to(device)  # Move hidden states to device\n","    enc_hiddens, (enc_h_hidden, enc_c_hidden) = encoder(input_batch, enc_h_hidden, enc_c_hidden)\n","\n","    # Initial decoder input (SOS token for each sentence in batch)\n","    decoder_input = torch.LongTensor(1, input_batch.shape[1]).fill_(output_lang.word_to_index[\"SOS\"]).to(device)\n","    dec_h_hidden, dec_c_hidden = enc_h_hidden, enc_c_hidden\n","\n","    # Loss criterion (NLLLoss)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    logits = []  # Store logits for NLL loss calculation\n","\n","    # Decode each time step\n","    for i in range(target_batch.shape[0]):\n","        pred, (dec_h_hidden, dec_c_hidden) = decoder(decoder_input, dec_h_hidden, dec_c_hidden, enc_hiddens)\n","        logits.append(pred)  # Collect logits for each time step\n","\n","        # Get the top predicted token\n","        _, topi = pred.topk(1, dim=1)\n","        ni = topi.view(1, -1)\n","\n","        # Set next decoder input to predicted token\n","        decoder_input = ni.to(device)  # Move to device\n","\n","        # Convert predicted tokens to words\n","        pred_sentence = [output_lang.index_to_word.get(idx.item(), '<UNK>') for idx in ni[0]]\n","        all_predictions.append(\" \".join(pred_sentence))\n","\n","    # Create reference sentences from target_batch\n","    for j in range(target_batch.shape[1]):  # Iterate over batch size\n","        ref_sentence = [output_lang.index_to_word.get(word.item(), '<UNK>') for word in target_batch[:, j]]\n","        all_references.append(\" \".join(ref_sentence))\n","\n","    # Convert logits to tensor [batch_size, seq_length, vocab_size]\n","    logits = torch.stack(logits, dim=1).to(device)\n","\n","    # Reshape target_batch to [batch_size, seq_length] for criterion compatibility\n","    target_batch = target_batch.transpose(0, 1)\n","\n","\n","    loss = criterion(logits.view(-1, logits.shape[-1]), target_batch.reshape(-1))\n","\n","    # Calculate batch Word Error Rate (WER)\n","    batch_wer = sum(calculate_wer(ref, pred) for ref, pred in zip(all_references, all_predictions)) / len(all_predictions)\n","\n","    return loss.item(), batch_wer\n"]},{"cell_type":"code","execution_count":null,"id":"19d2e55b","metadata":{"id":"19d2e55b"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"id":"706409f1","metadata":{"id":"706409f1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b188b1c7","metadata":{"id":"b188b1c7"},"outputs":[],"source":["import torch\n","\n","# Test function with GPU support\n","def test(test_batches, encoder, decoder, output_lang, device='cuda'):\n","    with torch.no_grad():\n","        test_loss = 0\n","        total_wer = 0  # Accumulates total WER over all batches\n","\n","        for batch in test_batches:\n","            # Pad and move batches to the specified device\n","            input_batch, target_batch = pad_batch(batch)\n","            input_batch = input_batch.to(device)\n","            target_batch = target_batch.to(device)\n","\n","            # Run the test batch on the GPU\n","            batch_loss, batch_wer = test_batch(input_batch, target_batch, encoder, decoder, output_lang, device=device)\n","\n","            # Accumulate the batch loss and WER\n","            test_loss += batch_loss\n","            total_wer += batch_wer  # Add batch WER to total WER\n","\n","        avg_wer = total_wer / len(test_batches)  # Average WER for the entire test set\n","\n","        return test_loss / len(test_batches), avg_wer\n"]},{"cell_type":"code","execution_count":null,"id":"c41a04ee-27d7-432f-aa9d-172f9732af5d","metadata":{"id":"c41a04ee-27d7-432f-aa9d-172f9732af5d"},"outputs":[],"source":["'''Returns the predicted translation of a given input sentence. Predicted\n","translation is trimmed to length of cutoff_length argument'''\n","\n","def evaluate(encoder, decoder, sentence, cutoff_length=100):\n","    with torch.no_grad():\n","        input_variable = tensorFromSentence(input_lang, sentence)\n","        input_variable = input_variable.view(-1, 1)\n","        enc_h_hidden, enc_c_hidden = encoder.create_init_hiddens(1)\n","\n","        enc_hiddens, enc_outputs = encoder(input_variable, enc_h_hidden, enc_c_hidden)\n","\n","        decoder_input = Variable(torch.LongTensor(1, 1).fill_(output_lang.word_to_index.get(\"SOS\")).cuda()) if use_cuda \\\n","                        else Variable(torch.LongTensor(1, 1).fill_(output_lang.word_to_index.get(\"SOS\")))\n","        dec_h_hidden = enc_outputs[0]\n","        dec_c_hidden = enc_outputs[1]\n","\n","        decoded_words = []\n","\n","        # Print type of trim (or cutoff_length) to debug\n","        # print(f\"Type of trim: {type(cutoff_length)}\")  # Check the type of cutoff_length\n","\n","        for di in range(cutoff_length):\n","            pred, dec_outputs = decoder(decoder_input, dec_h_hidden, dec_c_hidden, enc_hiddens)\n","\n","            topv, topi = pred.topk(1, dim=1)\n","            ni = topi.item()\n","            if ni == output_lang.word_to_index.get(\"EOS\"):\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index_to_word[ni])\n","\n","            decoder_input = Variable(torch.LongTensor(1, 1).fill_(ni).cuda()) if use_cuda \\\n","                            else Variable(torch.LongTensor(1, 1).fill_(ni))\n","            dec_h_hidden = dec_outputs[0]\n","            dec_c_hidden = dec_outputs[1]\n","\n","        output_sentence = ' '.join(decoded_words)\n","\n","        return output_sentence\n"]},{"cell_type":"code","execution_count":null,"id":"939d8fb5-baa5-408f-85f3-3ee5e7bbc590","metadata":{"id":"939d8fb5-baa5-408f-85f3-3ee5e7bbc590"},"outputs":[],"source":["'''Evaluates prediction translations for a specified number (n) of sentences\n","chosen randomly from a list of passed sentence pairs. Returns three sentences\n","in the format:\n","                 input sentence\n","                correct translation\n","                  predicted translation'''\n","\n","def evaluate_randomly(encoder, decoder, pairs, n=2, trim=100):\n","\tfor i in range(n):\n","\t\tpair = random.choice(pairs)\n","\t\tprint('Input: ', pair[0])\n","\t\tprint('Actual translation: ', pair[1])\n","\t\toutput_sentence = evaluate(encoder, decoder, pair[0],cutoff_length=100)\n","\t\tprint('Predicted translation: ', output_sentence)\n","\t\tprint('')\n","\t\tif create_txt:\n","\t\t\tf = open(print_to, 'a', encoding='utf-8')\n","\t\t\tf.write(\"\\n \\\n","\t\t\t\tInput :  %s \\n \\\n","\t\t\t\tActual translation:  %s \\n \\\n","\t\t\t\tPredicted translation:  %s \\n\" % (pair[0], pair[1], output_sentence))\n","\t\t\tf.close()"]},{"cell_type":"code","execution_count":null,"id":"4536180c-63f8-4c25-8697-031b76f4c7ba","metadata":{"id":"4536180c-63f8-4c25-8697-031b76f4c7ba"},"outputs":[],"source":["'''Used to plot the progress of training. Plots the loss value vs. time'''\n","\n","\n","def showPlot(times, losses, output_file_name, wer_values=None):\n","    plt.figure()\n","    plt.subplot(2, 1, 1)\n","    plt.plot(times, losses['train set'], label='Train Loss')\n","    if 'test set' in losses:\n","        plt.plot(times, losses['test set'], label='Test Loss')\n","    plt.xlabel('Time (minutes)')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    if wer_values:\n","        plt.subplot(2, 1, 2)\n","        plt.plot(times, wer_values['test set'], label='Test WER')\n","        plt.xlabel('Time (minutes)')\n","        plt.ylabel('WER')\n","        plt.legend()\n","\n","    plt.savefig(output_file_name + '_losses_wer.png')\n","    plt.show()\n","\n","'''prints the current memory consumption'''\n","def mem():\n","\tif use_cuda:\n","\t\tmem = torch.cuda.memory_allocated()/1e7\n","\telse:\n","\t\tmem = psutil.cpu_percent()\n","\tprint('Current mem usage:')\n","\tprint(mem)\n","\treturn \"Current mem usage: %s \\n\" % (mem)\n","\n","'''converts a time measurement in seconds to hours'''\n","def asHours(s):\n","\tm = math.floor(s / 60)\n","\th = math.floor(m / 60)\n","\ts -= m * 60\n","\tm -= h * 60\n","\treturn '%dh %dm %ds' % (h, m, s)"]},{"cell_type":"code","execution_count":null,"id":"9f10fd3b","metadata":{"id":"9f10fd3b"},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","import os\n","import time\n","\n","# Train and test function with GPU support\n","def train_and_test(epochs, test_eval_every, plot_every, learning_rate,\n","                   lr_schedule, train_pairs, test_pairs, input_lang,\n","                   output_lang, batch_size, test_batch_size, encoder, decoder,\n","                   trim,save_interval=1, path=\"50k_model.pth\", device='cuda'):\n","    # save_interval = int(save_interval)\n","    save_interval=1\n","    save_interval=int(save_interval)\n","    print(type(save_interval))\n","    print(\"Starting training...\")\n","    times = []\n","    losses = {'train set': [], 'test set': []}\n","    wer_values = {'train set': [], 'test set': []}  # Track WER\n","\n","    print(f\"Number of training pairs: {len(train_pairs)}\")\n","\n","    # Move encoder and decoder to the specified device (GPU)\n","    encoder.to(device)\n","    decoder.to(device)\n","\n","    # Load checkpoint if it exists\n","    start_epoch = 0\n","    if os.path.exists(path):\n","        checkpoint = torch.load(path, map_location=device)\n","        encoder.load_state_dict(checkpoint['encoder_state_dict'])\n","        decoder.load_state_dict(checkpoint['decoder_state_dict'])\n","        start_epoch = checkpoint['epoch'] + 1\n","        encoder_optimizer = checkpoint['encoder_optimizer']\n","        decoder_optimizer = checkpoint['decoder_optimizer']\n","        print(f\"Resuming from epoch {start_epoch}\")\n","    else:\n","        encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","        decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","        # encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=1e-4)\n","        # decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=1e-4)\n","\n","    # Prepare criterion and test batches, and move to the specified device\n","    criterion = nn.CrossEntropyLoss()\n","    test_batches, longest_seq, n_o_b = batchify(test_pairs, input_lang,\n","                                                output_lang, test_batch_size,\n","                                                shuffle_data=False)\n","\n","    start = time.time()\n","    for i in range(start_epoch, epochs):\n","        # Adjust learning rate if needed\n","        if i in lr_schedule.keys():\n","            learning_rate /= lr_schedule[i]\n","            for param_group in encoder_optimizer.param_groups:\n","                param_group['lr'] = learning_rate\n","            for param_group in decoder_optimizer.param_groups:\n","                param_group['lr'] = learning_rate\n","\n","        encoder.train()\n","        decoder.train()\n","\n","        # Batchify and train for this epoch, moving batches to the device\n","        batches, longest_seq, n_o_b = batchify(train_pairs, input_lang,\n","                                               output_lang, batch_size,\n","                                               shuffle_data=True)\n","\n","        # Training step on GPU\n","        train_loss = train(batches, encoder, decoder, encoder_optimizer,\n","                           decoder_optimizer, criterion, output_lang, device=device)\n","\n","        now = time.time()\n","        print(f\"Epoch: {i+1}\\nLearning Rate: {learning_rate}\\nTime: {asHours(now - start)}\\nTrain Loss: {train_loss}\")\n","\n","        # Evaluate on the test set if needed\n","        if (i + 1) % test_eval_every == 0:\n","            if test_pairs:\n","                test_loss, test_wer = test(test_batches, encoder, decoder, output_lang, device=device)\n","                print(f\"Test set loss: {test_loss}, Test set WER: {test_wer}\")\n","                if create_txt:\n","                    with open(print_to, 'a') as f:\n","                        f.write(f\"Test Loss: {test_loss}, Test WER: {test_wer}\\n\")\n","                evaluate_randomly(encoder, decoder, test_pairs, trim, output_lang)\n","            else:\n","                evaluate_randomly(encoder, decoder, train_pairs, trim, output_lang)\n","\n","        # Update plotting data\n","        if (i + 1) % plot_every == 0:\n","            times.append((time.time() - start) / 60)\n","            losses['train set'].append(train_loss)\n","            if test_pairs:\n","                losses['test set'].append(test_loss)\n","                wer_values['test set'].append(test_wer)  # Track test WER\n","            showPlot(times, losses, output_file_name, wer_values)  # Include WER in the plot\n","\n","        # Save checkpoint at specified intervals\n","        if (i + 1) % save_interval == 0:\n","            checkpoint = {\n","                'epoch': i,\n","                'encoder_state_dict': encoder.state_dict(),\n","                'decoder_state_dict': decoder.state_dict(),\n","                'encoder_optimizer': encoder_optimizer,\n","                'decoder_optimizer': decoder_optimizer\n","            }\n","            torch.save(checkpoint, path)\n","            print(f\"Checkpoint saved at epoch {i+1}\")\n","\n","    # Save final weights\n","    torch.save(encoder.state_dict(), output_file_name + \"_enc_weights.pt\")\n","    torch.save(decoder.state_dict(), output_file_name + \"_dec_weights.pt\")\n","    print(\"Training complete.\")\n"]},{"cell_type":"code","execution_count":null,"id":"13065141","metadata":{"id":"13065141"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"09886d99-23f7-4b0d-a2ce-61d0ee09864b","metadata":{"id":"09886d99-23f7-4b0d-a2ce-61d0ee09864b"},"outputs":[],"source":["\n","\n","input_lang_name = 'en'\n","output_lang_name = 'nep'\n","\n","dataset = 'english_nepali_pairs'\n","\n","\n","raw_data_file_path = ('added_cleaned_length10_filtered_95k_pairs.txt',)\n","\n","\n","reverse=False\n","\n","\"\"\"Remove sentences from dataset that are longer than trim (in either language)\"\"\"\n","trim = 10\n","\n","\"\"\"max number of words in the vocabulary for both languages\"\"\"\n","max_vocab_size= 50000\n","\n","\n","perc_train_set = 0.8\n","\n","\n","\"\"\"denotes how often to evaluate a loss on the test set and print\n","sample predictions on the test set.\n","if no test set, simply prints sample predictions on the train set.\"\"\"\n","test_eval_every = 1\n","\n","\"\"\"denotes how often to plot the loss values of train and test (if applicable)\"\"\"\n","plot_every = 1\n","\n","\"\"\"if true creates a txt file of the output\"\"\"\n","create_txt = True\n","\n","# Hyperparameters\n","\n","bidirectional = False\n","if bidirectional:\n","\tdirections = 2\n","else:\n","\tdirections = 1\n","\n","\"\"\"number of layers in both the Encoder and Decoder\"\"\"\n","layers = 3\n","\n","\"\"\"Hidden size of the Encoder and Decoder\"\"\"\n","hidden_size = 728\n","\"\"\"Dropout value for Encoder and Decoder\"\"\"\n","dropout = 0.1\n","\n","\"\"\"Training set batch size\"\"\"\n","batch_size = 64\n","\n","\"\"\"Test set batch size\"\"\"\n","test_batch_size = 64\n","\n","\"\"\"number of epochs (full passes through the training data)\"\"\"\n","epochs = 30\n","\n","\"\"\"Initial learning rate\"\"\"\n","learning_rate= 1\n","\n","\n","lr_schedule = {10:100, 20:100,25:100}\n","\n","criterion = nn.CrossEntropyLoss()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3e8cb870-e3c9-4f76-a64a-e79d1e52d9b6","metadata":{"id":"3e8cb870-e3c9-4f76-a64a-e79d1e52d9b6"},"outputs":[],"source":["\n","\n","save_interval=1\n","\n","path=\"50k_model.pth\""]},{"cell_type":"code","execution_count":null,"id":"843eb1f2","metadata":{"id":"843eb1f2"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"id":"53b10b01-9a94-4092-8761-2173dddd8bca","metadata":{"id":"53b10b01-9a94-4092-8761-2173dddd8bca","outputId":"c4f53c67-04c3-4948-f8aa-584b4f6fe92c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading lines...\n","Read 95953 sentence pairs\n","Trimmed to 95721 sentence pairs\n","Counting words...\n","Train pairs: 86149\n","Test pairs: 9572\n","Counted Words -> Trimmed Vocabulary Sizes (w/ EOS and SOS tags):\n","en, 38601 -> 38604\n","nep, 91124 -> 31228\n","\n","Train Pairs #\n","86149\n","Current mem usage:\n","0.0\n","Current mem usage:\n","0.0\n","Encoder and Decoder Created\n","Current mem usage:\n","0.0\n","Cuda being used\n","Number of epochs: 30\n","Current mem usage:\n","40.5630464\n","<class 'int'>\n","Starting training...\n","Number of training pairs: 86149\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_26756\\3886347517.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(path, map_location=device)\n"]},{"name":"stdout","output_type":"stream","text":["Resuming from epoch 30\n","Training complete.\n"]}],"source":["\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\"\"\"for plotting of the loss\"\"\"\n","plt.switch_backend('agg')\n","\n","output_file_name = \"testdata.%s_trim.%s_vocab.%s_directions.%s_layers.%s_hidden.%s_dropout.%s_learningrate.%s_batch.%s_epochs.%s\" % (dataset,trim,max_vocab_size,directions,layers,hidden_size,dropout,learning_rate,batch_size,epochs)\n","\n","if create_txt:\n","\tprint_to = output_file_name+'.txt'\n","\twith open(print_to, 'w+', encoding='utf-8') as f:\n","\t\tf.write(\"Starting Training \\n\")\n","else:\n","\tprint_to = None\n","\n","input_lang, output_lang, train_pairs, test_pairs = prepareData(\n","    input_lang_name, output_lang_name, raw_data_file_path,\n","    max_vocab_size=max_vocab_size, reverse=reverse, trim=trim, perc_train_set=perc_train_set, print_to=print_to)\n","print('Train Pairs #')\n","print(len(train_pairs))\n","\n","\n","\n","parser = argparse.ArgumentParser(description='PyTorch Wikitext-2 RNN/LSTM Language Model')\n","parser.add_argument('--clip', type=float, default=0.25,\n","                    help='gradient clipping')\n","args = parser.parse_args()\n","\n","mem()\n","\n","if create_txt:\n","\twith open(print_to, 'a', encoding='utf-8') as f:\n","\t\tf.write(\"\\nRandom Train Pair: %s \\n\\nRandom Test Pair: %s \\n\\n\"\n","            % (random.choice(train_pairs),random.choice(test_pairs)\n","               if test_pairs else \"None\"))\n","\t\tf.write(mem())\n","\n","\n","\"\"\"create the Encoder\"\"\"\n","encoder = EncoderRNNManual(input_lang.vocab_size, hidden_size, layers=layers,\n","                     dropout=dropout, bidirectional=bidirectional)\n","\n","\"\"\"create the Decoder\"\"\"\n","decoder = DecoderAttnManual(hidden_size, output_lang.vocab_size, layers=layers,\n","                      dropout=dropout, bidirectional=bidirectional)\n","\n","print('Encoder and Decoder Created')\n","mem()\n","\n","if use_cuda:\n","\tprint('Cuda being used')\n","\tencoder = encoder.cuda()\n","\tdecoder = decoder.cuda()\n","\n","print('Number of epochs: '+str(epochs))\n","\n","if create_txt:\n","\twith open(print_to, 'a', encoding='utf-8') as f:\n","\t\tf.write('Encoder and Decoder Created\\n')\n","\t\tf.write(mem())\n","\t\tf.write(\"Number of epochs %s \\n\" % (epochs))\n","\n","# train_and_test(epochs, test_eval_every, plot_every, learning_rate, lr_schedule,\n","#                train_pairs, test_pairs, input_lang, output_lang, batch_size,\n","#                test_batch_size, encoder, decoder, criterion, trim)\n","\n","\n","\n","train_and_test(epochs, test_eval_every, plot_every,\n","               learning_rate, lr_schedule, train_pairs,\n","               test_pairs, input_lang, output_lang,\n","               batch_size, test_batch_size, encoder,\n","               decoder,trim, save_interval, path)"]},{"cell_type":"code","execution_count":null,"id":"d88a2dd3-6d37-4171-8178-678eca790e7c","metadata":{"id":"d88a2dd3-6d37-4171-8178-678eca790e7c","outputId":"b43812d5-aff7-478f-f4e1-a81a1c4103a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_26756\\4035307562.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  encoder.load_state_dict(torch.load(output_file_name+'_enc_weights.pt'))\n","C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_26756\\4035307562.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  decoder.load_state_dict(torch.load(output_file_name+'_dec_weights.pt'))\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# loading saved weight\n","\n","encoder.load_state_dict(torch.load(output_file_name+'_enc_weights.pt'))\n","decoder.load_state_dict(torch.load(output_file_name+'_dec_weights.pt'))\n","\n"]},{"cell_type":"code","execution_count":null,"id":"758cd8bc-cc57-4e44-972e-eab22ab82032","metadata":{"id":"758cd8bc-cc57-4e44-972e-eab22ab82032","outputId":"a218787c-7d13-47c1-bc26-bed6d8cec861"},"outputs":[{"data":{"text/plain":["EncoderRNNManual(\n","  (embedder): Embedding(38604, 728)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (lstm_cell): LSTM(728, 728, num_layers=3, dropout=0.1)\n","  (fc): Linear(in_features=728, out_features=728, bias=True)\n",")"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["encoder.eval()  # Set to evaluation mode\n"]},{"cell_type":"code","execution_count":null,"id":"aef7a729-d28f-408f-9a21-dd9cddd0ff92","metadata":{"id":"aef7a729-d28f-408f-9a21-dd9cddd0ff92","outputId":"86b6c20f-c99a-43a4-b21b-3360c6364495"},"outputs":[{"data":{"text/plain":["DecoderAttnManual(\n","  (embedder): Embedding(31228, 728)\n","  (dropout_layer): Dropout(p=0.1, inplace=False)\n","  (score_learner): Linear(in_features=728, out_features=728, bias=True)\n","  (lstm_cell): LSTM(728, 728, num_layers=3, dropout=0.1)\n","  (context_combiner): Linear(in_features=1456, out_features=728, bias=True)\n","  (tanh): Tanh()\n","  (output): Linear(in_features=728, out_features=31228, bias=True)\n","  (soft): Softmax(dim=1)\n","  (log_soft): LogSoftmax(dim=1)\n",")"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["decoder.eval()  # Set to evaluation mode"]},{"cell_type":"code","execution_count":null,"id":"8ce60b9d-2c32-4295-8e47-8d5e0be2faf9","metadata":{"id":"8ce60b9d-2c32-4295-8e47-8d5e0be2faf9","outputId":"de0d1cde-e6ab-4354-cd06-ea6b1485401d"},"outputs":[{"data":{"text/plain":["'‡§â‡§π‡§æ‡§Å‡§≤‡•á ‡§∏‡§ö‡•á‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ ‡§≠‡§®‡•ç‡§®‡•á ‡§∏‡§ö‡•á‡§§ ‡§ó‡§∞‡•ç‡§®‡•Å‡§™‡§∞‡•ç‡§õ  <EOS>'"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["\n","outside_sent = \"he should aware\"\n","outside_sent = normalizeString(outside_sent)\n","evaluate(encoder, decoder, outside_sent, cutoff_length=20)"]},{"cell_type":"code","execution_count":null,"id":"2808da4d","metadata":{"id":"2808da4d","outputId":"d3081d28-6aa0-49d0-c064-2e227c596ffb"},"outputs":[{"data":{"text/plain":["'‡§Ø‡•ã ‡§≠‡§®‡•ç‡§¶‡§æ ‡§ß‡•á‡§∞‡•à ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã ‡§ó‡§∞‡•ç‡§® ‡§∏‡§ï‡•ç‡§õ‡•Å <EOS>'"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["\n","outside_sent = \"i can do much better than this\"\n","outside_sent = normalizeString(outside_sent)\n","evaluate(encoder, decoder, outside_sent, cutoff_length=20)"]},{"cell_type":"code","execution_count":null,"id":"0d70b61c-7d08-4d0c-a878-683a554d3360","metadata":{"id":"0d70b61c-7d08-4d0c-a878-683a554d3360","outputId":"c8d63a7f-403e-4cd5-d6bc-ed79bfe92b27"},"outputs":[{"data":{"text/plain":["'‡§π‡§æ‡§≤‡•à ‡§∏‡§Æ‡§Ø‡§Æ‡§æ ‡§§‡§æ‡§™‡§ï‡•ç‡§∞‡§Æ ‡§¶‡•á‡§ñ‡§ø‡§è‡§ï‡•ã ‡§§‡§æ‡§™‡§ï‡•ç‡§∞‡§Æ ‡§∏‡•ç‡§µ‡§æ‡§≠‡§æ‡§µ‡§ø‡§ï ‡§õ‡•à‡§®  <EOS>'"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["\n","outside_sent = \"temperature seen in recent decades are not natural\"\n","outside_sent = normalizeString(outside_sent)\n","evaluate(encoder, decoder, outside_sent, cutoff_length=20)"]},{"cell_type":"code","execution_count":null,"id":"89bb0f9b","metadata":{"id":"89bb0f9b","outputId":"3d4707b7-565f-4c02-9e43-b5c4121fc318"},"outputs":[{"data":{"text/plain":["'‡§â‡§®‡§ï‡•ã ‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï ‡§Æ‡§æ ‡§ú‡•á‡§≤ <UNK> <UNK> ‡§¶‡§ø‡§® ‡§≠‡§è‡§ï‡•ã ‡§•‡§ø‡§Ø‡•ã  <EOS>'"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["outside_sent = \"Her alternative was 90 days in jail\"\n","outside_sent = normalizeString(outside_sent)\n","evaluate(encoder, decoder, outside_sent, cutoff_length=20)"]},{"cell_type":"code","execution_count":null,"id":"84b725e0","metadata":{"id":"84b725e0","outputId":"ac9610a5-b2f2-4665-d93e-dd800ec779f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU score for the sentence: 1.2213386697554703e-77\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\acer\\Desktop\\yotahola\\env_name\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"data":{"text/plain":["'‡§®‡•á‡§™‡§æ‡§≤ ‡§¶‡•á‡§∂ ‡§π‡•ã  <EOS>'"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","outside_sent = \"Nepal is a country\"\n","outside_sent = normalizeString(outside_sent)\n","\n","# Run the evaluation function to get the model's predicted output\n","predicted_sent = evaluate(encoder, decoder, outside_sent, cutoff_length=10)\n","reference_words = \"‡§®‡•á‡§™‡§æ‡§≤ ‡§¶‡•á‡§∂ ‡§π‡•ã \"\n","\n","# Normalize and tokenize the sentences for BLEU score calculation\n","reference_words = reference_words.split()  # The original input as the reference\n","predicted_words = predicted_sent.split()  # Predicted output from the model\n","\n","# Remove EOS token from the end of predicted sentence if it's there\n","eos_token = \"<EOS>\"  # Define your EOS token\n","if predicted_words[-1] == eos_token:\n","    predicted_words = predicted_words[:-1]  # Exclude EOS from the prediction\n","\n","# Calculate BLEU score between the reference and predicted sentences\n","bleu_score = sentence_bleu([reference_words], predicted_words)\n","print(\"BLEU score for the sentence:\", bleu_score)\n","\n","predicted_sent"]},{"cell_type":"code","execution_count":null,"id":"1d539b8a","metadata":{"id":"1d539b8a","outputId":"45a303b9-c813-454d-d301-36c1078bb6f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU score for the sentence: 0\n"]},{"data":{"text/plain":["['‡§®‡•á‡§™‡§æ‡§≤', '‡§¶‡•á‡§∂', '‡§π‡•ã', 'eos']"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","# def normalizeString(sentence):\n","#     # Implement your normalization logic here, e.g., lowercasing and removing punctuation\n","#     return sentence.lower()\n","\n","# Normalize the input sentence\n","outside_sent = \"Nepal is a country\"\n","outside_sent = normalizeString(outside_sent)\n","\n","# Run the evaluation function to get the model's predicted output\n","# Replace `evaluate` with your actual evaluation function\n","predicted_sent = evaluate(encoder, decoder, outside_sent, cutoff_length=10)\n","\n","# Define the reference sentence\n","reference_words = \"\"\n","# Normalize and tokenize the reference and predicted sentences\n","reference_words = normalizeString(reference_words).split()  # Reference sentence as a list of words\n","predicted_words = normalizeString(predicted_sent).split()  # Predicted sentence as a list of words\n","\n","# Remove EOS token from the predicted sentence if it exists\n","eos_token = \"<eos>\"  # Define your EOS token\n","if eos_token in predicted_words:\n","    predicted_words = predicted_words[:predicted_words.index(eos_token)]  # Remove EOS and everything after\n","\n","# Apply smoothing for BLEU score calculation\n","smooth_fn = SmoothingFunction().method1\n","\n","# Calculate BLEU score\n","bleu_score = sentence_bleu([reference_words], predicted_words, smoothing_function=smooth_fn)\n","print(\"BLEU score for the sentence:\", bleu_score)\n","predicted_words"]},{"cell_type":"code","execution_count":null,"id":"d18dd2f2","metadata":{"id":"d18dd2f2","outputId":"65e734ea-22bf-4d45-fa52-42d2abef4960"},"outputs":[{"name":"stdout","output_type":"stream","text":["BLEU score for the sentence: 0.3976353643835253\n"]},{"data":{"text/plain":["'‡§®‡•á‡§™‡§æ‡§≤ ‡§¶‡•á‡§∂ ‡§π‡•ã  <EOS>'"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","# def normalizeString(sentence):\n","#     # Implement your normalization logic here, e.g., lowercasing and removing punctuation\n","#     return sentence.lower()\n","\n","# Normalize the input sentence\n","outside_sent = \"Nepal is a country\"\n","outside_sent = normalizeString(outside_sent)\n","\n","# Run the evaluation function to get the model's predicted output\n","# Replace `evaluate` with your actual evaluation function\n","predicted_sent = evaluate(encoder, decoder, outside_sent, cutoff_length=10)\n","\n","# Define the reference sentence\n","reference_words = \"‡§®‡•á‡§™‡§æ‡§≤ ‡§¶‡•á‡§∂ ‡§π‡•ã  \"\n","\n","# Normalize and tokenize the reference and predicted sentences\n","reference_words = normalizeString(reference_words).split()  # Reference sentence as a list of words\n","predicted_words = normalizeString(predicted_sent).split()  # Predicted sentence as a list of words\n","eos_token = \"<eos>\"  # Define your EOS token\n","if eos_token in predicted_words:\n","    predicted_words = predicted_words[:predicted_words.index(eos_token)]\n","# Apply smoothing for BLEU score calculation\n","smooth_fn = SmoothingFunction().method1\n","\n","# Calculate BLEU score\n","bleu_score = sentence_bleu([reference_words], predicted_words, smoothing_function=smooth_fn)\n","print(\"BLEU score for the sentence:\", bleu_score)\n","predicted_sent\n"]},{"cell_type":"code","execution_count":null,"id":"8e93c83e","metadata":{"id":"8e93c83e","outputId":"81c9b20b-3e74-4f98-c723-ef934d771418"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\acer\\desktop\\yotahola\\env_name\\lib\\site-packages (3.9.1)\n","Requirement already satisfied: click in c:\\users\\acer\\desktop\\yotahola\\env_name\\lib\\site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\acer\\desktop\\yotahola\\env_name\\lib\\site-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\acer\\desktop\\yotahola\\env_name\\lib\\site-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in c:\\users\\acer\\desktop\\yotahola\\env_name\\lib\\site-packages (from nltk) (4.67.0)\n","Requirement already satisfied: colorama in c:\\users\\acer\\desktop\\yotahola\\env_name\\lib\\site-packages (from click->nltk) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n","[notice] To update, run: c:\\Users\\acer\\Desktop\\yotahola\\env_name\\Scripts\\python.exe -m pip install --upgrade pip\n"]}],"source":["pip install nltk"]},{"cell_type":"code","execution_count":null,"id":"1f27529a","metadata":{"id":"1f27529a","outputId":"5240e2f5-f2d1-45f5-91d4-53dc93ef0ff7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Filtered file saved at: PR_combined_filtered.txt\n"]}],"source":["# Define file paths\n","english_file_path = 'PR_improved.en'\n","nepali_file_path = 'PR_improved.ne'\n","output_file_path = 'PR_combined_filtered.txt'\n","\n","# Read the content of the files\n","with open(english_file_path, 'r', encoding='utf-8') as en_file, \\\n","     open(nepali_file_path, 'r', encoding='utf-8') as ne_file:\n","    english_sentences = en_file.readlines()\n","    nepali_sentences = ne_file.readlines()\n","\n","# Ensure both files have the same number of lines\n","min_length = min(len(english_sentences), len(nepali_sentences))\n","\n","# Filter and combine the sentences\n","filtered_data = []\n","for i in range(min_length):\n","    english_sentence = english_sentences[i].strip()\n","    nepali_sentence = nepali_sentences[i].strip()\n","    if len(english_sentence.split()) < 11 and len(nepali_sentence.split()) < 11:\n","        filtered_data.append(f\"{english_sentence}\\t{nepali_sentence}\")\n","\n","# Write the filtered data to a new file\n","with open(output_file_path, 'w', encoding='utf-8') as output_file:\n","    output_file.write(\"\\n\".join(filtered_data))\n","\n","print(f\"Filtered file saved at: {output_file_path}\")\n"]},{"cell_type":"code","execution_count":null,"id":"d76c5d89","metadata":{"id":"d76c5d89"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"env_name","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}